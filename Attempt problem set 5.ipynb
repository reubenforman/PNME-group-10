{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Quadratic Programming\n",
    "1 a i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for b = 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using finite differences: 2.30223222267748e-9\n",
      "Results for b = 100:\n",
      "RMSE using finite differences: 9.261150370712152e-8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for b = 1000:\n",
      "RMSE using finite differences: 1.065152628847392e-6\n"
     ]
    }
   ],
   "source": [
    "using FiniteDiff\n",
    "using Optim\n",
    "using ForwardDiff\n",
    "using ForwardDiff: gradient, hessian, jacobian\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "\n",
    "# Define the Lagrangian function\n",
    "function lagrangian(domain, a, b, r)\n",
    "    x = domain[1:end-1]\n",
    "    λ = domain[end]\n",
    "    \n",
    "    n = length(x)\n",
    "    sum_terms = 0\n",
    "    for i in 1:n-1\n",
    "        sum_terms += a * (1 - x[i])^2 + b * (x[i+1] - x[i]^2)^2\n",
    "    end\n",
    "    \n",
    "    constraint_term = 0\n",
    "    for i in 1:n\n",
    "        constraint_term += λ * (x[i]^2 - r)\n",
    "    end\n",
    "    \n",
    "    return sum_terms + constraint_term\n",
    "end\n",
    "\n",
    "# Define the gradient of the Lagrangian using ForwardDiff\n",
    "function gradient_lagrangian(domain, a, b, r)\n",
    "    x = domain[1:end-1]\n",
    "    λ = domain[end]\n",
    "    \n",
    "    ∇L_x = ForwardDiff.gradient(x -> lagrangian([x; λ], a, b, r), x)\n",
    "    \n",
    "    return ∇L_x\n",
    "end\n",
    "\n",
    "# Define the function to sample points uniformly on the unit square\n",
    "function sample_points_uniformly(n_points, n_dimensions)\n",
    "    points = rand(n_points, n_dimensions)\n",
    "    return points\n",
    "end\n",
    "\n",
    "# Function to compute gradient using finite differences\n",
    "function finite_diff_lagrangian(domain, a, b, r; ϵ=1e-15)\n",
    "    x = domain[1:end-1]\n",
    "    λ = domain[end]\n",
    "    \n",
    "    ∇L_x = FiniteDiff.finite_difference_gradient(x -> lagrangian([x; λ], a, b, r), x)\n",
    "    \n",
    "    return ∇L_x\n",
    "end\n",
    "\n",
    "function test_gradients(n, k, a, b, r)\n",
    "    points = sample_points_uniformly(k, n)  # Sample points uniformly\n",
    "    errors_fd = zeros(k)\n",
    "    errors_forward_diff = zeros(k)\n",
    "\n",
    "    for i in 1:k\n",
    "        domain = points  # Append λ = 0 to the sampled point\n",
    "        ∇L_x_fd = finite_diff_lagrangian(domain, a, b, r)\n",
    "\n",
    "        ∇L_x_forward_diff = gradient_lagrangian(domain, a, b, r)\n",
    "        \n",
    "        # Calculate RMSE for finite differences\n",
    "        errors_fd[i] = sqrt(mean((∇L_x_fd .- ∇L_x_forward_diff).^2))\n",
    "        \n",
    "        # Calculate RMSE for ForwardDiff\n",
    "    end\n",
    "\n",
    "    return errors_fd\n",
    "end\n",
    "\n",
    "using Statistics\n",
    "# Test the gradients\n",
    "n = 5\n",
    "k = 100\n",
    "a = 1\n",
    "b_values = [1, 100, 1000]  # Different values of b to test\n",
    "\n",
    "for b in b_values\n",
    "    errors_fd, errors_forward_diff = test_gradients(n, k, a, b, n)\n",
    "    println(\"Results for b = $b:\")\n",
    "    println(\"RMSE using finite differences: $(mean(errors_fd))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 a ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(fx = 0.0, x = [1.0, 1.0], iter = 2)\n"
     ]
    }
   ],
   "source": [
    "# Implement Newton's very specifically for this lagrangian method\n",
    "function newton(x0, a, b, r, λ; tol = 10e-6, itermax = 100, trace=false)\n",
    "    x = copy(x0)\n",
    "    \n",
    "\n",
    "    err  = Inf\n",
    "    iter = 0\n",
    "    while ! (err < tol) && iter < itermax\n",
    "        # Calculate the gradient and the Hessian of the Lagrangian\n",
    "        fx  = lagrangian([x; λ], 1, 1, r)\n",
    "\n",
    "        Df   = ForwardDiff.gradient(x -> lagrangian([x; λ], a, b, r), x)\n",
    "        if Df == zeros(length(x0))\n",
    "            return (;fx = lagrangian([x; λ], a, b, r), x, iter)\n",
    "            break\n",
    "        end\n",
    "\n",
    "        D²f  = ForwardDiff.hessian(x -> lagrangian([x; λ], a, b, r), x)\n",
    "\n",
    "        # search direction\n",
    "        sk = -D²f \\ Df\n",
    "\n",
    "        # update x\n",
    "        x′ = x + sk\n",
    "        \n",
    "        # Check for convergence\n",
    "        err = norm(x′ - x)\n",
    "\n",
    "        # copy x′ to be old x and start again\n",
    "        x .= x′\n",
    "        iter += 1\n",
    "\n",
    "        trace && @info \"Trace Information\" iter x fx = lagrangian([x; λ], 1, 1, r)\n",
    "    end\n",
    "\n",
    "    return (;fx = lagrangian([x; λ], 1, 1, r), x, iter)\n",
    "end\n",
    "\n",
    "a=1\n",
    "b=1\n",
    "r=2\n",
    "λ = 0\n",
    "x_0 = zeros(2)\n",
    "println(newton(x_0, a, b, r, λ ))\n",
    "# x0 only seems to work with floats, so just being aware of this is useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 a iii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different cases for initial guess values, when does it work, potentially changing λ to see if it has \n",
    "#effects. KEEPING r=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 a iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALLOWED TO CHANGE r=2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalty method\n",
    "1 bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solve_penalty (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using ForwardDiff\n",
    "using Optim\n",
    "\n",
    "a = 10\n",
    "b = 10\n",
    "r = 10\n",
    "function Rosenbrock(x, a, b, r)\n",
    "    sum = 0\n",
    "    for i in 1:length(x)-1\n",
    "        calc = a*(1-x[i])^2 + b*(x[i+1]-x[i])^2\n",
    "        sum += calc\n",
    "    end\n",
    "    return sum\n",
    "end\n",
    "\n",
    "function constraint(x, r)\n",
    "    sum = 0\n",
    "    for i in 1:length(x)\n",
    "        sum += x[i]^2\n",
    "    end\n",
    "    return sum - r\n",
    "end\n",
    "\n",
    "function solve_penalty(P, x0, a, b, r)\n",
    "    # Set up the penalized objective \n",
    "    function objective(x)\n",
    "        return Rosenbrock(x, a, b, r) + P * norm(constraint(x, r))^2\n",
    "    end\n",
    "\n",
    "    # Solve with Newton's method\n",
    "    ret = optimize(objective, x0, LBFGS())\n",
    "\n",
    "    # Keep things interpretable\n",
    "    return ret\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Status: success\n",
      "\n",
      " * Candidate solution\n",
      "    Final objective value:     1.000000e+14\n",
      "\n",
      " * Found with\n",
      "    Algorithm:     L-BFGS\n",
      "\n",
      " * Convergence measures\n",
      "    |x - x'|               = 0.00e+00 ≤ 0.0e+00\n",
      "    |x - x'|/|x'|          = NaN ≰ 0.0e+00\n",
      "    |f(x) - f(x')|         = NaN ≰ 0.0e+00\n",
      "    |f(x) - f(x')|/|f(x')| = NaN ≰ 0.0e+00\n",
      "    |g(x)|                 = 0.00e+00 ≤ 1.0e-08\n",
      "\n",
      " * Work counters\n",
      "    Seconds run:   0  (vs limit Inf)\n",
      "    Iterations:    0\n",
      "    f(x) calls:    1\n",
      "    ∇f(x) calls:   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(solve_penalty(1e12, zeros(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have n=10 we set $x_0 = [0]*10$, we see that with the large value of the penalty, we congerge to $x_{i}\\text{'s} = -1$ which because we know the true minimum is when $x_{i}\\text{'s} = 1$ we know this is not the answer we are looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 b ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "penalty_method (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function penalty_method(x0, a, b, r; tol = 1e-12, γ = 10, trace = false)\n",
    "    iter = 0\n",
    "    num_evals = 0\n",
    "    P = 1\n",
    "    x = copy(x0)\n",
    "    while true\n",
    "        # Solve with penalty parameter P\n",
    "        ret = solve_penalty(P, x, a, b, r)\n",
    "\n",
    "        # Keep track of the total number of function evals (really, Newton steps in this case)\n",
    "        num_evals += ret.iterations\n",
    "\n",
    "        # If P is large enough, we're done\n",
    "        P > 1e12 && break\n",
    "\n",
    "        # Otherwise we keep going, using the solution as a warmstart\n",
    "        # Increment P up\n",
    "        x .= ret.minimizer  # Update x with the minimizer found\n",
    "        gx = constraint(x, r)\n",
    "        P *= γ\n",
    "        iter += 1\n",
    "\n",
    "        trace && @info \"Trace\" iter P penalty_violation = gx\n",
    "    end\n",
    "\n",
    "    return (; fx = Rosenbrock(x, a, b, r), x, iter, num_evals)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Trace\n",
      "│   iter = 1\n",
      "│   P = 10\n",
      "│   penalty_violation = -1.6370904631912708e-11\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 2\n",
      "│   P = 100\n",
      "│   penalty_violation = -1.6370904631912708e-11\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 3\n",
      "│   P = 1000\n",
      "│   penalty_violation = -1.6370904631912708e-11\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 4\n",
      "│   P = 10000\n",
      "│   penalty_violation = -1.6370904631912708e-11\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 5\n",
      "│   P = 100000\n",
      "│   penalty_violation = -1.6370904631912708e-11\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 6\n",
      "│   P = 1000000\n",
      "│   penalty_violation = -1.6370904631912708e-11\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 7\n",
      "│   P = 10000000\n",
      "│   penalty_violation = -1.6370904631912708e-11\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 8\n",
      "│   P = 100000000\n",
      "│   penalty_violation = -1.6370904631912708e-11\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 9\n",
      "│   P = 1000000000\n",
      "│   penalty_violation = -1.6370904631912708e-11\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 10\n",
      "│   P = 10000000000\n",
      "│   penalty_violation = -1.6370904631912708e-11\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Trace\n",
      "│   iter = 11\n",
      "│   P = 100000000000\n",
      "│   penalty_violation = -1.6370904631912708e-11\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 12\n",
      "│   P = 1000000000000\n",
      "│   penalty_violation = -1.6370904631912708e-11\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 13\n",
      "│   P = 10000000000000\n",
      "│   penalty_violation = -1.6370904631912708e-11\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(fx = 1.0261426364130259e-20, x = [0.9999999999898055, 0.9999999999897117, 1.0000000000014042, 0.9999999999989639, 1.0000000000071068, 0.9999999999948097, 1.0000000000080815, 0.9999999999988493, 0.9999999999982205, 1.0000000000048612], iter = 13, num_evals = 29)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x0 = zeros(10)\n",
    "penalty_ret = penalty_method(x0, tol=1e-12, trace=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When n=r the penalty constraint method works it out almost immediately, however this is due to the efficiency of the Newton method rather than the penalty method. When $n \\neq r$ there is not the option for all the x's to be 1 as this would violate the constraint. So it converges towards a different solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Trace\n",
      "│   iter = 1\n",
      "│   P = 10\n",
      "│   penalty_violation = 0.0\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 2\n",
      "│   P = 100\n",
      "│   penalty_violation = 0.0\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 3\n",
      "│   P = 1000\n",
      "│   penalty_violation = 0.0\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 4\n",
      "│   P = 10000\n",
      "│   penalty_violation = 0.0\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 5\n",
      "│   P = 100000\n",
      "│   penalty_violation = 0.0\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 6\n",
      "│   P = 1000000\n",
      "│   penalty_violation = 0.0\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 7\n",
      "│   P = 10000000\n",
      "│   penalty_violation = 0.0\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 8\n",
      "│   P = 100000000\n",
      "│   penalty_violation = 0.0\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 9\n",
      "│   P = 1000000000\n",
      "│   penalty_violation = 0.0\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 10\n",
      "│   P = 10000000000\n",
      "│   penalty_violation = 0.0\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 11\n",
      "│   P = 100000000000\n",
      "│   penalty_violation = 0.0\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 12\n",
      "│   P = 1000000000000\n",
      "│   penalty_violation = 0.0\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n",
      "┌ Info: Trace\n",
      "│   iter = 13\n",
      "│   P = 10000000000000\n",
      "│   penalty_violation = 0.0\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(fx = 0.0, x = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], iter = 13, num_evals = 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x0 = 1*ones(10)\n",
    "penalty_ret = penalty_method(x0, tol=1e-12, trace=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Lagrangian\n",
    "1 c i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "augmented_lagrangian (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function augmented_lagrangian_inner(f, g, P, λ, x0)\n",
    "    function objective(x)\n",
    "        gx = g(x)\n",
    "        f(x) + 0.5 * P * norm(gx)^2 + dot(λ, gx)\n",
    "    end\n",
    "\n",
    "    # Solve the augmented problem\n",
    "    ret = optimize(objective, x0, LBFGS())\n",
    "    return ret.minimizer\n",
    "end\n",
    "\n",
    "function augmented_lagrangian(f, g, x0; tol = 1e-8, γ = 10, trace=false)\n",
    "    gx = g(x0)\n",
    "    λ = ones(size(gx))  # Initialize λ as zeros\n",
    "    P = 1.0\n",
    "    x = copy(x0)\n",
    "    num_evals = 0\n",
    "    iter = 0\n",
    "\n",
    "    while true \n",
    "        # Solve the inner problem \n",
    "        x′ = augmented_lagrangian_inner(f, g, P, λ, x)\n",
    "        num_evals += 1\n",
    "        iter += 1\n",
    "        \n",
    "        # Update λ\n",
    "        gx = g(x′)\n",
    "        λ′ = λ .+ gx .* P\n",
    "\n",
    "        # Check if we're violating the constraints\n",
    "        err = norm(λ′ .- λ)^2\n",
    "        if err < tol\n",
    "            break\n",
    "        else # otherwise keep going\n",
    "            P *= γ\n",
    "            x .= x′\n",
    "            λ .= λ′\n",
    "            trace && @info \"Trace\" iter P err penalty_violation = gx\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return (fx = f(x), x, λ, num_evals, iter)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Trace\n",
      "│   iter = 1\n",
      "│   P = 10.0\n",
      "│   err = 0.4946585212453418\n",
      "│   penalty_violation = -0.7033196437220717\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:38\n",
      "┌ Info: Trace\n",
      "│   iter = 2\n",
      "│   P = 100.0\n",
      "│   err = 0.08142201196563384\n",
      "│   penalty_violation = -0.02853454256960042\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:38\n",
      "┌ Info: Trace\n",
      "│   iter = 3\n",
      "│   P = 1000.0\n",
      "│   err = 0.00012746851424601653\n",
      "│   penalty_violation = -0.00011290195491930888\n",
      "└ @ Main c:\\Users\\reube\\OneDrive\\Desktop\\Econ_programming\\Week_6\\Attempt problem set 5.ipynb:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(fx = 2.525538859999929e-9, x = [0.9999955244115429, 0.9999955226802132, 0.9999955174862142, 0.9999955036355321, 0.9999954672774264, 0.9999953720536301, 0.9999951227399121, 0.9999944700214786, 0.9999927611772851, 0.9999882873561534], λ = "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill(4.473508999325304e-5), num_evals = 4, iter = 4)\n"
     ]
    }
   ],
   "source": [
    "println(augmented_lagrangian(Rosenbrock, constraint, zeros(10), trace=true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Transformation\n",
    "1 d i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     7.039971e-18\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 1.48e-03 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 4.42e+05 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 1.37e-06 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 1.95e+11 ≰ 0.0e+00\n",
       "    |g(x)|                 = 4.19e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    4\n",
       "    f(x) calls:    14\n",
       "    ∇f(x) calls:   14\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function h(Z, r)\n",
    "    n = length(Z) + 1\n",
    "    X = zeros(n)\n",
    "\n",
    "    exp_Z = exp.(Z)\n",
    "\n",
    "    exp_sum = sum(exp_Z)\n",
    "\n",
    "    for i in 1:n-1\n",
    "        X[i] = (exp(Z[i]) / (1 + exp_sum))^(1/2)\n",
    "    end\n",
    "    X[n] = (1 / (1 + exp_sum))^(1/2)\n",
    "    return sqrt(r) * X\n",
    "end\n",
    "\n",
    "function h_inv(X)\n",
    "    n = length(X)\n",
    "    Z = zeros(n-1)\n",
    "    for i in 1:n-1\n",
    "        Z[i] = 2 * log(X[i]/X[n])\n",
    "    end\n",
    "    return Z\n",
    "end\n",
    "\n",
    "function Rosenbrock(X, a, b)\n",
    "    sum = 0\n",
    "    for i in 1:length(X)-1\n",
    "        sum += (a*(1-X[i])^2 + b*(X[i+1]-X[i]^2)^2)\n",
    "    end\n",
    "    return sum\n",
    "end\n",
    "\n",
    "function constraint(X, r)\n",
    "    sum = 0\n",
    "    for i in 1:length(X)\n",
    "        sum += X[i]^2\n",
    "    end\n",
    "    return sum - r\n",
    "end\n",
    "\n",
    "function Rosenbrock_unconstrained(Z, a, b, r)\n",
    "    X = h(Z, r)\n",
    "    return Rosenbrock(X, a, b)\n",
    "end\n",
    "\n",
    "using Optim\n",
    "a = 1\n",
    "b = 1\n",
    "r = 2\n",
    "z0 = [5.0]\n",
    "\n",
    "# Define the objective function to pass to Optim\n",
    "objective_function(Z) = Rosenbrock_unconstrained(Z, a, b, r)\n",
    "\n",
    "# Call the optimization routine\n",
    "result = optimize(objective_function, z0, LBFGS())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.1",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
